{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "part_01_solutions.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/iust-deep-learning/tensorflow-2-tutorial/blob/master/part_02_tensors_and_basic_ops/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YS8LoLU0OQha",
    "colab_type": "text"
   },
   "source": [
    "# Part #2: Tensors and Basic Operations\n",
    "\n",
    "\n",
    "TensorFlow 2.0 Tutorial by IUST\n",
    "\n",
    "*   Last Update: Jan 2020\n",
    "*   Official Page: https://github.com/iust-deep-learning/tensorflow-2-tutorial\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSj39l8gcIA8",
    "colab_type": "text"
   },
   "source": [
    "Please run the following cell before going through the rest of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RFC1dEyMcFq2",
    "colab_type": "code",
    "cellView": "both",
    "outputId": "71d2b8c0-bcc8-41d6-8f51-66c043d03b75",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Install TensorFlow\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2IsaWZ4KZhWk"
   },
   "source": [
    "## Tensors\n",
    "Tensors are the main element that you will use to define your desired computations. Generally speaking, Tensors are n-dimensional arrays with a specified data type. That is, each component of the Tensors has the same data type (e.g., int32 or float32), and such a data type is always known across the computation. Various methods can create tensors, two of which–that is–**constants and variables** are the most common ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2yc4AMXCC3f",
    "colab_type": "text"
   },
   "source": [
    "**Constants**\n",
    "\n",
    "Use methods such as `tf.ones(...)`, `tf.zeros(...)`, `tf.eye(...)`, and etc..\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F2NS5woVCJdi",
    "colab_type": "code",
    "outputId": "b8d92234-5671-4d7c-84ea-779ea3009bc6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    }
   },
   "source": [
    "a = tf.ones(shape=(2,3), dtype=tf.int32)\n",
    "a"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 20:43:15.688164: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\narray([[1, 1, 1],\n       [1, 1, 1]], dtype=int32)>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZCUdl_pDm6o",
    "colab_type": "text"
   },
   "source": [
    "Or define them by manually passing Python/numpy data types ([More info](https://www.tensorflow.org/api_docs/python/tf/constant))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qUYZVnZcEA9O",
    "colab_type": "code",
    "outputId": "9eb409ec-30e8-4fde-dc31-542774c1b9f9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    }
   },
   "source": [
    "b = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"b =\",b);\n",
    "\n",
    "npvar = np.array([\"hello\", \"world\"])\n",
    "c = tf.constant(npvar)\n",
    "print(\"\\nc =\", c)\n",
    "\n",
    "d = tf.constant(10.0, shape=[2,5])\n",
    "print(\"\\nd =\", d)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]], shape=(3, 3), dtype=int32)\n",
      "\n",
      "c = tf.Tensor([b'hello' b'world'], shape=(2,), dtype=string)\n",
      "\n",
      "d = tf.Tensor(\n",
      "[[10. 10. 10. 10. 10.]\n",
      " [10. 10. 10. 10. 10.]], shape=(2, 5), dtype=float32)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9xm-JZeGU2M",
    "colab_type": "text"
   },
   "source": [
    "You can also use random initializers ([More info](https://www.tensorflow.org/api_docs/python/tf/random)). You may re-run the cell to generate another set of random values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iTpw8Xn1KuTx",
    "colab_type": "code",
    "outputId": "2211d576-20bd-4a50-ad72-24c3dac89539",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    }
   },
   "source": [
    "e = tf.random.normal(shape=[2, 3], mean=0.0, stddev=1.0)\n",
    "print(\"e =\", e)\n",
    "\n",
    "f = tf.random.uniform( shape=[2,3], minval=0,maxval=10,dtype=tf.int32)\n",
    "print(\"\\nf =\", f)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e = tf.Tensor(\n",
      "[[-0.07342033  0.977618    0.80144495]\n",
      " [ 0.25326458  0.30247217  0.25575098]], shape=(2, 3), dtype=float32)\n",
      "\n",
      "f = tf.Tensor(\n",
      "[[3 4 3]\n",
      " [7 3 4]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZrV5FsiMkE-",
    "colab_type": "text"
   },
   "source": [
    "**Variables**\n",
    "\n",
    "Variables hold a persistant shared state across your computation. The most common use case of Variables is the model's trainable parameters.\n",
    "\n",
    "The only way to create variables is to use `tf.Variable(<required-initial-value>, name=<optional-name>)` class. Tensorflow uses the `initial-value` to infer the shape and the type of the variable. Please note that shape and the type of variable, once specified, cannot be changed during the computation.  Tensorflow cleans up variables when the runtime changes its scope and the variable is not referenced anymore. Therefore, it is your responsibility to keep track of variables in your Tensorflow program (Good news: Tensorflow's high-level APIs handles that automatically)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "stnuFXfBSM8q",
    "colab_type": "code",
    "outputId": "cd0689bc-a5a7-4288-96af-8f3b861c7abb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    }
   },
   "source": [
    "w = tf.Variable(20., name=\"my_var01\")\n",
    "print('w =', w)\n",
    "\n",
    "initializer = tf.initializers.GlorotUniform()\n",
    "x = tf.Variable(initializer(shape=(2, 5)), name=\"my_var02\")\n",
    "print('\\nx =', x)\n",
    "\n",
    "y = tf.Variable(tf.zeros([5]), name='my_var03')\n",
    "print('\\ny =', y)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "w = <tf.Variable 'my_var01:0' shape=() dtype=float32, numpy=20.0>\n",
      "\n",
      "x = <tf.Variable 'my_var02:0' shape=(2, 5) dtype=float32, numpy=\n",
      "array([[-0.45070884,  0.56897163,  0.29169297, -0.77587044, -0.4456739 ],\n",
      "       [ 0.1657275 , -0.9256539 , -0.86812764,  0.05088377,  0.19746172]],\n",
      "      dtype=float32)>\n",
      "\n",
      "y = <tf.Variable 'my_var03:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gOVcgI_bxCy",
    "colab_type": "text"
   },
   "source": [
    "Variables' APIs are mostly similar to Tensors. Hence, we can treat them like a standard Tensor."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TxYFPFB0cvTt",
    "colab_type": "code",
    "outputId": "a4c99c7a-c872-47f9-df1e-1e2b2b8673f0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    }
   },
   "source": [
    "v = w + 1.  # v is a tf.Tensor and is calculated as the result of\n",
    "            # a mathematical expression that is based on a variable(w).\n",
    "            # tf.Variable gets automatically converted to a tf.Tensor \n",
    "            # representing its value when it is envolved in a expression.\n",
    "\n",
    "print(\"v =\", v)\n",
    "print(f\"v's type = {type(v)}\")\n",
    "print(f\"w's type = {type(w)}\")"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "v = tf.Tensor(21.0, shape=(), dtype=float32)\n",
      "v's type = <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "w's type = <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvWuU3cne2ch",
    "colab_type": "text"
   },
   "source": [
    "To change the variable's current value, you can use methods such as `assign` and `assign_add`. ([More info](https://www.tensorflow.org/api_docs/python/tf/Variable))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WOKSX8wPfVz-",
    "colab_type": "code",
    "outputId": "892d534b-d8c2-4d17-bc26-ea860bb94609",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "w.assign(v)\n",
    "w.assign_add(v)\n",
    "print('w =', w)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "w = <tf.Variable 'my_var01:0' shape=() dtype=float32, numpy=42.0>\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xh8brxauZhW9"
   },
   "source": [
    "### Rank, Shape, and Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "487399b0-9342-4273-aef8-25635b05c4e4",
    "id": "WsZONY5NZhW-",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    }
   },
   "source": [
    "print(f\"a = \\n{a}\")\n",
    "print(\"a.dtype =\", a.dtype)\n",
    "print(\"a.shape =\", a.shape)\n",
    "print(\"a.rank =\", len(a.shape))\n",
    "# or...\n",
    "print(\"\\na.shape =\", tf.shape(a))\n",
    "print(\"a.rank =\", tf.rank(a)) \n",
    "# What is the difference?\n",
    "\n",
    "print(\"\\ne (before type conversion) =\", e)\n",
    "e_int = tf.cast(e, tf.int32)\n",
    "print(\"e (after type conversion) =\", e_int)\n",
    "\n",
    "# Convert a tf.Tensor object to an np.array instance\n",
    "e_np = e_int.numpy()\n",
    "print(f\"\\ntype(e_np) = {type(e_np)}\")\n",
    "e_np"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = \n",
      "[[1 1 1]\n",
      " [1 1 1]]\n",
      "a.dtype = <dtype: 'int32'>\n",
      "a.shape = (2, 3)\n",
      "a.rank = 2\n",
      "\n",
      "a.shape = tf.Tensor([2 3], shape=(2,), dtype=int32)\n",
      "a.rank = tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "e (before type conversion) = tf.Tensor(\n",
      "[[-0.07342033  0.977618    0.80144495]\n",
      " [ 0.25326458  0.30247217  0.25575098]], shape=(2, 3), dtype=float32)\n",
      "e (after type conversion) = tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 0 0]], shape=(2, 3), dtype=int32)\n",
      "\n",
      "type(e_np) = <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0, 0, 0],\n       [0, 0, 0]], dtype=int32)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhsqXGEbZhXA"
   },
   "source": [
    "## Tensor manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgr3tYFmZhXB"
   },
   "source": [
    "**Element-Wise Operations**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "e511ff74-8b81-4e26-b465-b163dd1ad153",
    "id": "N9JveG2eZhXC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    }
   },
   "source": [
    "t1 = tf.constant([[0, 0, 0], [0, 1, 1], [0, 1, 1]])\n",
    "t2 = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print('t1 + t2 =', t1 + t2)\n",
    "print('t2 - t1 =', t2 - t1)\n",
    "print('t1 * t2 =', t1 * t2)\n",
    "print('t1 / t2 =', t1 / t2)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "t1 + t2 = tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [ 4  6  7]\n",
      " [ 7  9 10]], shape=(3, 3), dtype=int32)\n",
      "t2 - t1 = tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 4 5]\n",
      " [7 7 8]], shape=(3, 3), dtype=int32)\n",
      "t1 * t2 = tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 5 6]\n",
      " [0 8 9]], shape=(3, 3), dtype=int32)\n",
      "t1 / t2 = tf.Tensor(\n",
      "[[0.         0.         0.        ]\n",
      " [0.         0.2        0.16666667]\n",
      " [0.         0.125      0.11111111]], shape=(3, 3), dtype=float64)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiaRcO0CZhXG"
   },
   "source": [
    "**Broadcasting** Broadcasting happens in arithmetic operations encountering tensors with different shapes. Basically, Tensorflow \"broadcasts\" the smaller tensor across the larger matrix so that they become compatible. Think of broadcasting as repeating the values of the smaller tensor without actually needlessly copying them. In fact, Broadcasting provides an easy way to implement algorithms efficiently.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/kazemnejad/tensorflow-2-tutorial/master/resources/part_01_broadcasting.jpg\" width=\"500\" />\n",
    "\n",
    "<a href=\"https://www.tutorialspoint.com/numpy/numpy_broadcasting.htm\">[source]</a>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "4c19cbdd-26e8-47b7-d711-8980c4a6a8be",
    "id": "1Qmd3icsZhXG",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    }
   },
   "source": [
    "t1 = tf.constant([1, 2, 3, 4])\n",
    "print(\"t1 + 100 =\", t1 + 100)\n",
    "\n",
    "# (m, n) + (1, n)\n",
    "t1 = tf.constant([[1, 2, 3], \n",
    "                  [4, 5, 6]])\n",
    "t2 = tf.constant([[100, 200, 300]])\n",
    "print(f\"\\nt1.shape = {t1.shape}, t2.shape = {t2.shape}\")\n",
    "print(\"t1 + t2 =\", t1 + t2)\n",
    "\n",
    "# (m, n) + (n, 1)\n",
    "t1 = tf.constant([[1, 2, 3], \n",
    "                  [4, 5, 6]])\n",
    "t2 = tf.constant([[100], \n",
    "                  [200]])\n",
    "print(f\"\\nt1.shape = {t1.shape}, t2.shape = {t2.shape}\")\n",
    "print(\"t1 + t2 =\", t1 + t2)\n",
    "\n",
    "# (1, n) + (m, 1)\n",
    "t1 = tf.constant([[1, 2, 3]])\n",
    "t2 = tf.constant([[100], \n",
    "                  [200]])\n",
    "print(f\"\\nt1.shape = {t1.shape}, t2.shape = {t2.shape}\")\n",
    "print(\"t1 + t2 =\", t1 + t2)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 + 100 = tf.Tensor([101 102 103 104], shape=(4,), dtype=int32)\n",
      "\n",
      "t1.shape = (2, 3), t2.shape = (1, 3)\n",
      "t1 + t2 = tf.Tensor(\n",
      "[[101 202 303]\n",
      " [104 205 306]], shape=(2, 3), dtype=int32)\n",
      "\n",
      "t1.shape = (2, 3), t2.shape = (2, 1)\n",
      "t1 + t2 = tf.Tensor(\n",
      "[[101 102 103]\n",
      " [204 205 206]], shape=(2, 3), dtype=int32)\n",
      "T2 tf.Tensor(\n",
      "[[100]\n",
      " [200]], shape=(2, 1), dtype=int32)\n",
      "\n",
      "t1.shape = (1, 3), t2.shape = (2, 1)\n",
      "t1 + t2 = tf.Tensor(\n",
      "[[101 102 103]\n",
      " [201 202 203]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "B6dbCFlUZhXJ",
    "colab": {}
   },
   "source": [
    "# General Rule\n",
    "\n",
    "# 1.  (m, n) matrix    +, -, *, /    (1, n) matrix   =(get copied)=>   (m, n)\n",
    "# 2.  (m, n) matrix    +, -, *, /    (m, 1) matrix   =(get copied)=>   (m, n)\n",
    "# 2.  (m, n) matrix    +, -, *, /    0D scalar       =(get copied)=>   (m, n)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5MHRmmuZhXL"
   },
   "source": [
    "**Matrix Multiplication**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "46ef2cd7-a4b1-4d32-b436-b8f89055a55b",
    "id": "jB1B2EuDZhXL",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    }
   },
   "source": [
    "t1 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = tf.constant([[10, 20], \n",
    "                  [30, 40],\n",
    "                  [50, 60]])\n",
    "print(\"tf.matmul(t1, t2) =\", tf.matmul(t1, t2))"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.matmul(t1, t2) = tf.Tensor(\n",
      "[[220 280]\n",
      " [490 640]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kudiYcSWZhXN"
   },
   "source": [
    "**Transposing**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "24c39655-9ac3-46a5-9552-e18a2aca357c",
    "id": "HirWaUbEZhXO",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    }
   },
   "source": [
    "# tf.transpose(t, perm) permutes the dimensions according to the `perm` parameter.\n",
    "t1 = tf.constant([[1, 2, 3], [4, 5, 6]]) # (2,3) -> (3, 2)\n",
    "print(\"tf.transpose(t1, [1, 0]) =\", tf.transpose(t1, perm=[1, 0])) \n",
    "\n",
    "# It also works in higher dimensions\n",
    "t1 = tf.ones(shape=(2, 5, 13))\n",
    "t1_t = tf.transpose(t1, perm=[0, 2, 1])\n",
    "print(f\"\\nt1_t.shape = {t1_t.shape}\")\n",
    "\n",
    "# You can permute the order of more than two dimensions at the same time.\n",
    "t1 = tf.ones(shape=(2, 5, 13))\n",
    "t1_t = tf.transpose(t1, perm=[2, 0, 1])\n",
    "print(f\"\\nt1_t.shape = {t1_t.shape}\")"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tf.transpose(t1, [1, 0]) = tf.Tensor(\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]], shape=(3, 2), dtype=int32)\n",
      "\n",
      "t1_t.shape = (2, 13, 5)\n",
      "\n",
      "t1_t.shape = (13, 2, 5)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZdBJMsVWZhXQ"
   },
   "source": [
    "**Reshaping**\n",
    "You can create a new tensor from an existing tensor with different shape but same values. The only rule is that the new tensor's size should be equal to that of the previous one."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "a34517b7-8c8d-4674-c7f7-91b42fc56d95",
    "id": "a4r141MYZhXR",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    }
   },
   "source": [
    "# Examples from https://www.tensorflow.org/api_docs/python/tf/reshape\n",
    "\n",
    "t = tf.constant([1, 2, 3, 4, 5, 6, 7, 8, 9]) # [9]\n",
    "print(f\"t_new = tf.reshape(t, [3, 3]); t_new => \\n {tf.reshape(t, [3, 3])}\")\n",
    "\n",
    "t = tf.constant([[[1, 1], [2, 2]],\n",
    "                [[3, 3], [4, 4]]]) # [2, 2, 2]\n",
    "print(f\"\\nt_new = tf.reshape(t, [2, 4]); t_new => \\n {tf.reshape(t, [2, 4])}\")\n",
    "\n",
    "# -1 can also be used to automatically calculate the shape\n",
    "t = tf.constant([[[1, 1, 1],\n",
    "                 [2, 2, 2]],\n",
    "                [[3, 3, 3],\n",
    "                 [4, 4, 4]],\n",
    "                [[5, 5, 5],\n",
    "                 [6, 6, 6]]]) # [3, 2, 3]\n",
    "\n",
    "# -1 => 18\n",
    "print(f\"\\nt_new = tf.reshape(t, [-1]); t_new => \\n {tf.reshape(t, [-1])}\")\n",
    "# -1 => 9\n",
    "print(f\"\\nt_new = tf.reshape(t, [2, -1]); t_new => \\n {tf.reshape(t, [2, -1])}\")\n",
    "# -1 => 2\n",
    "print(f\"\\nt_new = tf.reshape(t, [-1, 9]); t_new => \\n {tf.reshape(t, [-1, 9])}\")\n",
    "# -1 => 3\n",
    "print(f\"\\nt_new = tf.reshape(t, [2, -1, 3]); t_new => \\n {tf.reshape(t, [2, -1, 3])}\")\n",
    "\n",
    "# Convert to a scalar using shape `[]`\n",
    "t = tf.constant([5])\n",
    "print(f\"\\nt_new = tf.reshape(t, []); t_new => \\n {tf.reshape(t, [])}\")"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "t_new = tf.reshape(t, [3, 3]); t_new => \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "t_new = tf.reshape(t, [2, 4]); t_new => \n",
      " [[1 1 2 2]\n",
      " [3 3 4 4]]\n",
      "\n",
      "t_new = tf.reshape(t, [-1]); t_new => \n",
      " [1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6]\n",
      "\n",
      "t_new = tf.reshape(t, [2, -1]); t_new => \n",
      " [[1 1 1 2 2 2 3 3 3]\n",
      " [4 4 4 5 5 5 6 6 6]]\n",
      "\n",
      "t_new = tf.reshape(t, [-1, 9]); t_new => \n",
      " [[1 1 1 2 2 2 3 3 3]\n",
      " [4 4 4 5 5 5 6 6 6]]\n",
      "\n",
      "t_new = tf.reshape(t, [2, -1, 3]); t_new => \n",
      " [[[1 1 1]\n",
      "  [2 2 2]\n",
      "  [3 3 3]]\n",
      "\n",
      " [[4 4 4]\n",
      "  [5 5 5]\n",
      "  [6 6 6]]]\n",
      "\n",
      "t_new = tf.reshape(t, []); t_new => \n",
      " 5\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0QXxYoYZhXT"
   },
   "source": [
    "**Advanced Reshaping**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "bac886a2-1756-49c8-8ac0-c5226b91a732",
    "id": "DCGtzOuVZhXU",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    }
   },
   "source": [
    "# tf.tile(t, multiples) creates a new tensor by replicating `t` `multiples` times.\n",
    "t = tf.constant([1, 2, 3, 4]) # [4]\n",
    "print(f\"tf.tile(t, [2]) = \\n{tf.tile(t, [2])}\") # [8]\n",
    "\n",
    "t = tf.constant([[1, 2, 3, 4]]) # [1, 4]\n",
    "print(f\"\\ntf.tile(t, [3, 1]) = \\n{tf.tile(t, [3, 1])}\") # [3, 4]\n",
    "\n",
    "# tf.expand(t, axis) adds a new dimension to the tensor's shape (tensor's values does not change)\n",
    "# Examples from https://www.tensorflow.org/api_docs/python/tf/expand_dims\n",
    "\n",
    "t1 = tf.constant([1, 2,]) # [2]\n",
    "print(f\"\\ntf.shape(tf.expand_dims(t1, 0)) = {tf.shape(tf.expand_dims(t1, 0))}\")\n",
    "print(f\"tf.shape(tf.expand_dims(t1, 1)) = {tf.shape(tf.expand_dims(t1, 1))}\")\n",
    "print(f\"tf.shape(tf.expand_dims(t1, -1)) = {tf.shape(tf.expand_dims(t1, -1))}\")\n",
    "\n",
    "# 't2' is a tensor of shape [2, 3, 5]\n",
    "t2 = tf.ones(shape=[2, 3, 5])\n",
    "print(f\"\\ntf.shape(tf.expand_dims(t2, 0)) = {tf.shape(tf.expand_dims(t2, 0))}\")\n",
    "print(f\"tf.shape(tf.expand_dims(t2, 2)) = {tf.shape(tf.expand_dims(t2, 2))}\")\n",
    "print(f\"tf.shape(tf.expand_dims(t2, 3)) = {tf.shape(tf.expand_dims(t2, 3))}\")\n",
    "\n",
    "# tf.squeeze(a) exactly do the reverse operation: Removes all dimensions of size 1\n",
    "t3 = tf.ones(shape=[1, 2, 1, 3, 1, 1])\n",
    "print(f\"\\ntf.shape(tf.squeeze(t3)) = {tf.shape(tf.squeeze(t3))}\")"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tf.tile(t, [2]) = \n",
      "[1 2 3 4 1 2 3 4]\n",
      "\n",
      "tf.tile(t, [3, 1]) = \n",
      "[[1 2 3 4]\n",
      " [1 2 3 4]\n",
      " [1 2 3 4]]\n",
      "\n",
      "tf.shape(tf.expand_dims(t1, 0)) = [1 2]\n",
      "tf.shape(tf.expand_dims(t1, 1)) = [2 1]\n",
      "tf.shape(tf.expand_dims(t1, -1)) = [2 1]\n",
      "\n",
      "tf.shape(tf.expand_dims(t2, 0)) = [1 2 3 5]\n",
      "tf.shape(tf.expand_dims(t2, 2)) = [2 3 1 5]\n",
      "tf.shape(tf.expand_dims(t2, 3)) = [2 3 5 1]\n",
      "\n",
      "tf.shape(tf.squeeze(t3)) = [2 3]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OUwR4TKGZhXW"
   },
   "source": [
    "**Combining Tensors**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "0a76156a-4f0b-4a87-9d2b-af5cb0cec750",
    "id": "ICHNv2YrZhXW",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    }
   },
   "source": [
    "t1 = tf.constant([[1, 1, 1], [1, 1, 1]]) # [2, 3]\n",
    "t2 = tf.constant([[2, 2, 2], [2, 2, 2]]) # [2, 3]\n",
    "t3 = tf.constant([[3, 3, 3], [3, 3, 3]]) # [2, 3]\n",
    "\n",
    "print(f\"tf.concat([t1, t2, t3], axis=0) = \\n{tf.concat([t1, t2, t3], axis=0)}\") # [6, 3]\n",
    "print(f\"\\ntf.concat([t1, t2, t3], axis=1) = \\n{tf.concat([t1, t2, t3], axis=1)}\") # [2, 9]"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tf.concat([t1, t2, t3], axis=1) = \n",
      "[[1 1 1]\n",
      " [1 1 1]\n",
      " [2 2 2]\n",
      " [2 2 2]\n",
      " [3 3 3]\n",
      " [3 3 3]]\n",
      "\n",
      "tf.concat([t1, t2, t3], axis=1) = \n",
      "[[1 1 1 2 2 2 3 3 3]\n",
      " [1 1 1 2 2 2 3 3 3]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "8d9d3afc-e020-4304-ed7d-ad882221d143",
    "id": "U8a_w9WVZhXa",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    }
   },
   "source": [
    "t1 = tf.constant([1, 1, 1, 1])\n",
    "t2 = tf.constant([2, 2, 2, 2])\n",
    "t3 = tf.constant([3, 3, 3, 3])\n",
    "\n",
    "print(f\"tf.stack([t1, t2, t3], axis=0) = \\n{tf.stack([t1, t2, t3], axis=0)}\")\n",
    "print(f\"\\ntf.stack([t1, t2, t3], axis=1) = \\n{tf.stack([t1, t2, t3], axis=1)}\")"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tf.stack([t1, t2, t3], axis=1) = \n",
      "[[1 1 1 1]\n",
      " [2 2 2 2]\n",
      " [3 3 3 3]]\n",
      "\n",
      "tf.stack([t1, t2, t3], axis=1) = \n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AS9RM7PpZhXc"
   },
   "source": [
    "**Slicing and Indexing** "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "d5fd4731-f82b-4b9e-8da5-262141487380",
    "id": "E9kVyrNYZhXd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    }
   },
   "source": [
    "t = tf.random.uniform(shape=[4, 5, 6, 7], maxval=10, dtype=tf.int32)\n",
    "\n",
    "# same as Python lists and Numpy arrays\n",
    "t1 = t[1:3, 0, 3:, -2:-6:-1]\n",
    "print(\"t1 =\", t1)\n",
    "\n",
    "# same t[0, 0, :, :]\n",
    "t2 = t[0, :, :, 0]\n",
    "print(\"\\nt2 =\", t2)"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 = tf.Tensor(\n",
      "[[[7 0 5 3]\n",
      "  [1 8 9 7]\n",
      "  [9 4 6 9]]\n",
      "\n",
      " [[6 5 6 5]\n",
      "  [8 6 6 2]\n",
      "  [3 9 5 3]]], shape=(2, 3, 4), dtype=int32)\n",
      "\n",
      "t2 = tf.Tensor(\n",
      "[[[[0 8 1 7 2 0 0]\n",
      "   [9 0 0 9 1 7 6]\n",
      "   [6 1 8 8 8 6 6]\n",
      "   [7 9 0 4 8 6 7]\n",
      "   [4 8 2 3 4 6 2]\n",
      "   [0 4 0 9 0 5 5]]\n",
      "\n",
      "  [[2 1 6 2 5 2 7]\n",
      "   [0 5 6 2 2 3 9]\n",
      "   [9 6 9 5 4 0 8]\n",
      "   [4 2 0 0 9 3 5]\n",
      "   [4 5 7 8 8 3 7]\n",
      "   [3 9 7 1 9 9 7]]\n",
      "\n",
      "  [[6 9 7 5 9 9 3]\n",
      "   [0 3 8 6 5 7 0]\n",
      "   [9 3 5 5 3 4 4]\n",
      "   [5 5 0 3 0 7 6]\n",
      "   [8 5 0 4 2 2 2]\n",
      "   [4 8 5 4 2 7 9]]\n",
      "\n",
      "  [[7 0 9 2 9 0 1]\n",
      "   [8 9 3 8 5 6 9]\n",
      "   [0 8 6 4 6 9 8]\n",
      "   [2 6 4 5 9 0 5]\n",
      "   [0 9 3 6 2 9 0]\n",
      "   [2 4 5 9 7 2 4]]\n",
      "\n",
      "  [[5 1 2 5 6 8 7]\n",
      "   [5 0 4 0 9 9 9]\n",
      "   [3 7 7 7 7 4 4]\n",
      "   [5 5 7 9 0 7 1]\n",
      "   [9 3 1 9 8 5 8]\n",
      "   [6 3 9 9 9 3 1]]]\n",
      "\n",
      "\n",
      " [[[9 5 9 0 9 3 0]\n",
      "   [9 9 9 6 7 9 8]\n",
      "   [5 8 9 9 1 7 1]\n",
      "   [9 4 3 5 0 7 8]\n",
      "   [3 8 7 9 8 1 2]\n",
      "   [7 7 9 6 4 9 1]]\n",
      "\n",
      "  [[1 8 6 0 9 1 0]\n",
      "   [5 8 0 4 3 7 1]\n",
      "   [4 0 2 0 2 9 5]\n",
      "   [4 0 0 0 1 1 2]\n",
      "   [8 9 3 2 7 0 3]\n",
      "   [8 6 6 4 4 5 1]]\n",
      "\n",
      "  [[1 1 6 7 1 9 3]\n",
      "   [0 9 2 7 2 3 4]\n",
      "   [9 8 3 6 2 0 6]\n",
      "   [9 2 4 3 7 7 1]\n",
      "   [8 4 9 3 3 2 0]\n",
      "   [3 2 1 1 9 3 5]]\n",
      "\n",
      "  [[6 8 5 8 1 6 9]\n",
      "   [5 4 9 9 8 4 3]\n",
      "   [7 6 9 9 9 2 2]\n",
      "   [0 9 0 5 5 9 8]\n",
      "   [5 4 3 0 0 8 2]\n",
      "   [3 9 6 2 0 1 4]]\n",
      "\n",
      "  [[8 7 6 8 4 6 8]\n",
      "   [4 1 1 5 6 7 0]\n",
      "   [3 5 8 4 8 8 3]\n",
      "   [2 1 2 1 4 8 4]\n",
      "   [3 8 9 2 9 5 9]\n",
      "   [9 0 9 2 8 6 3]]]\n",
      "\n",
      "\n",
      " [[[8 6 4 4 4 0 5]\n",
      "   [0 0 9 2 4 3 5]\n",
      "   [6 9 2 8 4 6 1]\n",
      "   [8 6 5 6 5 6 9]\n",
      "   [3 6 2 6 6 8 6]\n",
      "   [4 1 3 5 9 3 2]]\n",
      "\n",
      "  [[4 1 9 8 7 5 7]\n",
      "   [5 3 5 0 7 3 8]\n",
      "   [1 6 3 0 1 0 5]\n",
      "   [0 2 5 5 4 5 6]\n",
      "   [1 7 1 6 2 1 8]\n",
      "   [5 2 7 2 3 6 3]]\n",
      "\n",
      "  [[5 6 0 7 8 2 4]\n",
      "   [6 2 8 3 9 3 9]\n",
      "   [5 0 5 9 1 7 0]\n",
      "   [6 1 4 7 2 8 7]\n",
      "   [9 3 2 7 8 6 7]\n",
      "   [9 7 6 8 7 3 2]]\n",
      "\n",
      "  [[0 6 8 6 9 7 8]\n",
      "   [2 0 3 1 2 0 8]\n",
      "   [2 9 8 2 6 9 4]\n",
      "   [1 3 7 7 2 0 6]\n",
      "   [6 3 2 0 2 5 8]\n",
      "   [1 3 5 9 0 5 9]]\n",
      "\n",
      "  [[1 9 3 8 9 4 1]\n",
      "   [6 6 0 9 2 4 8]\n",
      "   [7 9 6 5 5 5 1]\n",
      "   [2 8 6 0 6 1 1]\n",
      "   [0 3 5 1 9 6 8]\n",
      "   [2 2 7 7 5 8 1]]]\n",
      "\n",
      "\n",
      " [[[0 2 5 4 7 8 2]\n",
      "   [2 8 1 5 3 4 1]\n",
      "   [6 9 8 4 4 8 2]\n",
      "   [5 0 8 5 6 0 1]\n",
      "   [3 6 4 1 4 0 0]\n",
      "   [0 7 9 3 7 5 6]]\n",
      "\n",
      "  [[1 6 4 6 6 8 9]\n",
      "   [5 1 3 3 4 0 5]\n",
      "   [1 1 5 2 8 4 1]\n",
      "   [4 9 9 6 8 4 7]\n",
      "   [8 5 2 0 6 9 7]\n",
      "   [7 8 8 0 1 7 2]]\n",
      "\n",
      "  [[7 2 9 4 9 8 6]\n",
      "   [9 3 8 0 5 8 5]\n",
      "   [4 0 1 7 1 8 2]\n",
      "   [1 2 3 8 7 7 8]\n",
      "   [7 4 5 9 7 8 1]\n",
      "   [1 0 7 4 1 7 0]]\n",
      "\n",
      "  [[4 3 9 7 0 9 6]\n",
      "   [4 3 1 7 9 3 0]\n",
      "   [4 4 5 0 9 9 0]\n",
      "   [3 6 4 0 9 1 1]\n",
      "   [6 2 9 0 5 7 8]\n",
      "   [5 0 5 1 8 2 5]]\n",
      "\n",
      "  [[1 3 2 3 2 3 4]\n",
      "   [4 0 5 5 0 2 6]\n",
      "   [1 0 6 6 5 1 9]\n",
      "   [3 4 4 5 8 6 6]\n",
      "   [2 9 9 6 2 2 7]\n",
      "   [4 8 9 2 6 8 2]]]], shape=(4, 5, 6, 7), dtype=int32)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RRCxsNX8ZhXg"
   },
   "source": [
    "**Reducing**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "6c059df8-edba-48e4-f358-817bc3a9d7bd",
    "id": "vbw70C_XZhXg",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    }
   },
   "source": [
    "t = tf.constant([[1, 2, 3, 4], \n",
    "                 [1, 2, 3, 4]])\n",
    "\n",
    "# calculate the sum of all elements\n",
    "print(\"tf.reduce_sum(t) =\", tf.math.reduce_sum(t))\n",
    "\n",
    "# calculate the sum of all elements vertically \n",
    "print(\"tf.reduce_sum(t, axis=0) =\", tf.math.reduce_sum(t, axis=0))\n",
    "\n",
    "# calculate the sum of all elements horizontally\n",
    "print(\"tf.reduce_sum(t, axis=1) =\", tf.math.reduce_sum(t, axis=1))\n",
    "\n",
    "t1 = tf.random.uniform(shape=[3, 4], maxval=10, dtype=tf.int32)\n",
    "print(\"\\nt1 =\",t1)\n",
    "print(\"tf.reduce_min(t1) =\", tf.math.reduce_min(t1))\n",
    "print(\"tf.reduce_max(t1) =\", tf.math.reduce_max(t1))\n",
    "print(\"tf.reduce_mean(t1) =\", tf.math.reduce_mean(t1))"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tf.reduce_sum(t) = tf.Tensor(20, shape=(), dtype=int32)\n",
      "tf.reduce_sum(t, axis=0) = tf.Tensor([2 4 6 8], shape=(4,), dtype=int32)\n",
      "tf.reduce_sum(t, axis=1) = tf.Tensor([10 10], shape=(2,), dtype=int32)\n",
      "\n",
      "t1 = tf.Tensor(\n",
      "[[7 3 3 0]\n",
      " [8 2 5 1]\n",
      " [9 7 9 9]], shape=(3, 4), dtype=int32)\n",
      "tf.reduce_min(t1) = tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.reduce_max(t1) = tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.reduce_mean(t1) = tf.Tensor(5, shape=(), dtype=int32)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzJ99c_QhPI2",
    "colab_type": "text"
   },
   "source": [
    "### Exercise #1: Prime numbers diff\n",
    "We have a very special vector, where the `i`th element is equal to the absolute difference of `i`th prime number squared and `i+1`th prime number squared. For example,  the 1st element in this vector is $|2^2 - 3^2| = 5$. Create this vector using TensorFlow operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y8REnvFnnMuk",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "prime_numbers = tf.constant([2, 3, 5, 7, 11, 13, 17, 19, 23])\n",
    "shifted_prime_numbers = tf.concat([prime_numbers[1:], [29]], axis=0)\n",
    "\n",
    "# Put your answer here, complete the definition of Tensor `diff`\n",
    "# You may want to use tf.square and tf.abs\n",
    "diffs = tf.abs(tf.square(prime_numbers) - tf.square(shifted_prime_numbers))\n",
    "\n",
    "assert tf.math.reduce_all(diffs == tf.constant([5,  16,  24,  72,  48, 120,  72, 168, 312])).numpy()\n",
    "print(\"Passed!\")"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mw5Gp8Lp9gG",
    "colab_type": "text"
   },
   "source": [
    "### Exercise #2: Simulate 10 throwings of one die and one coin.\n",
    "Perform this simulation, and store its result in a `[10, 3]` shaped int32 tensor. Each row belongs to one simulation (that is, one roll of a six-sided die and one flip of a coin). The definition of each column is as follows:\n",
    "*   Column 1: the result of throwing the coin.\n",
    "*   Column 2: the result of throwing the die.\n",
    "*   Column 3: if we have head and the roll's result is bigger than 3, then it should be `1`, otherwise it should be `0`)\n",
    "\n",
    "For example, one of the rows might be something like  `[1, 4, 1]`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6ERImAmIs_Zj",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Write your answer here. \n",
    "# Complete the implementation of `simulation_result` tensor\n",
    "# You may need to use tf.math.greater and tf.math.equal \n",
    "die_roll = tf.random.uniform(shape=[10,1], maxval=7, minval=1, dtype=tf.int32)\n",
    "coin_flip = tf.random.uniform(shape=[10,1], maxval=2, minval=0, dtype=tf.int32)\n",
    "\n",
    "die_greater_3 = tf.cast(tf.greater(die_roll, 3), tf.int32)\n",
    "success = tf.cast(tf.math.equal(die_greater_3 + coin_flip, 2), tf.int32)\n",
    "\n",
    "simulation_result = tf.concat([coin_flip, die_roll, success], axis=1)\n",
    "simulation_result"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 3), dtype=int32, numpy=\narray([[1, 5, 1],\n       [1, 5, 1],\n       [1, 3, 0],\n       [1, 1, 0],\n       [1, 6, 1],\n       [0, 6, 0],\n       [1, 3, 0],\n       [0, 4, 0],\n       [1, 1, 0],\n       [0, 6, 0]], dtype=int32)>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ubj0ByCwVqs",
    "colab_type": "text"
   },
   "source": [
    "### Exercise #3: Normalized Euclidean Distance \n",
    "\n",
    "Suppose that we have two sets of d-dimensional vectors. Our goal is to calculate the normalized euclidean distance between each vector of these two sets. That is, given $S_1 \\in R^{m \\times d}$ and $S_1 \\in R^{n \\times d}$, we want to calculate the $X \\in R^{m \\times n}$. Euclidean distance between two vector V and W is calculated as follows:\n",
    "\n",
    "$$\n",
    "dist = \\sqrt{(V_1 - W_1)^2 + ... +\\:(W_d - W_d)^2}\n",
    "$$\n",
    "\n",
    "Please note that we want to calculate the normalized distance, which is within the [0, 1] range. Therefore, you should normalize the similarity scores across each row."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NhJU8za529IS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def euclidean_norm_distance(v, w):\n",
    "  # Write your answer here. \n",
    "  n = tf.shape(v)[0] # 3\n",
    "  m = tf.shape(w)[0] # 2\n",
    "\n",
    "  v = tf.tile(tf.expand_dims(v, 1), [1, m, 1]) # (n, m, d)\n",
    "  w = tf.tile(tf.expand_dims(w, 1), [1, n, 1]) # (m, n, d)\n",
    "  w = tf.transpose(w, [1, 0, 2]) # (n, m, d)\n",
    "\n",
    "  distances = (v - w) # (n, m, d)\n",
    "  distances = distances ** 2 # (n, m, d)\n",
    "  distances = tf.math.reduce_sum(distances, axis=2) # (n, m)\n",
    "  distances = tf.math.sqrt(distances) # (n, m)\n",
    "\n",
    "  sum_distances = tf.reshape(tf.math.reduce_sum(distances, axis=1), [-1, 1]) # (n, 1)\n",
    "  distances = distances / sum_distances # (n, m)\n",
    "\n",
    "  return distances"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "v4Vr57j_3ez2",
    "colab_type": "code",
    "outputId": "9cf3464b-2e8b-4ea5-e9ea-280004e153ec",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "t1 = tf.constant([[-1.8897635 ,  0.7396171 ,  0.4683413 ,  2.35642   , -0.8153529 ],\n",
    "       [ 1.3100415 ,  0.6090922 ,  0.70573515,  0.07053893, -0.20450763],\n",
    "       [-0.14293706, -0.94566655,  0.41517866,  0.9539284 , -0.9522885 ]])\n",
    "t2 = tf.constant([[ 0.4980808 ,  0.12677321, -1.6533084 ,  1.2168828 ,  0.351612  ],\n",
    "       [-0.35999015, -1.013327  , -1.4144444 ,  0.83520454,  1.4889846 ]])\n",
    "\n",
    "answer = tf.constant([[0.4718873, 0.5281127 ],\n",
    " [0.43739235, 0.5626077 ],\n",
    " [0.47395885, 0.52604115]])\n",
    "\n",
    "assert np.allclose(euclidean_norm_distance(t1, t2).numpy(), answer)\n",
    "print(\"Passed!\")"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bZ6N-jxiCFr",
    "colab_type": "text"
   },
   "source": [
    "## Final Assignment: Low-level MNIST CNN-Classifier\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJgFkqhCXKAJ",
    "colab_type": "text"
   },
   "source": [
    "You probably have implemented a neural network-based classifier many times. However, we want to implement a multi-layer CNN classifier using raw TensorFlow operations and matrix multiplication. No pre-defined CNN blocks are allowed. You cannot use Keras, Keras Sequence API, or its training loop. Instead, you should implement the training loop yourself.\n",
    "\n",
    "Assignment criteria:\n",
    "\n",
    "*   Implement a multi-layer CNN classifer\n",
    "*   Default Keras CNN modules are not permited\n",
    "*   Use `tf.GradientTape` to build your custom training loop\n",
    "\n",
    "*Hint: You may refer to [here](https://medium.com/@_init_/an-illustrated-explanation-of-performing-2d-convolutions-using-matrix-multiplications-1e8de8cd2544) to rewrite 2D Convolutions in terms of matrix multiplications.*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RMUnRMekYoUQ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# ..."
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tXo0f6BgZhYU"
   },
   "source": [
    "## References\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfUQc2aEYswq",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "*   Broadcasting in Python https://www.youtube.com/watch?v=tKcLaGdvabM\n",
    "*   https://colab.research.google.com/notebooks/mlcc/creating_and_manipulating_tensors.ipynb#scrollTo=ocwT0iXH-nhT\n",
    "*   https://tensorflow.org\n",
    "*   http://web.stanford.edu/class/cs20si/\n",
    "\n"
   ]
  }
 ]
}